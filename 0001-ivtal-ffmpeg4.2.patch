From 4c2a1ad470560af196acec6220209ee0be82c1da Mon Sep 17 00:00:00 2001
From: Wray151 <zheyuan.zhang@intel.com>
Date: Mon, 31 Oct 2022 07:34:56 -0400
Subject: [PATCH] IVTAL ffmpeg4.2 release/1.0

---
 fftools/ffmpeg.c           | 58 ++++++++++++++++++++++++++++++++++
 fftools/ffmpeg.h           |  1 +
 fftools/ffmpeg_opt.c       | 46 +++++++++++++++++++++++++++
 libavcodec/avcodec.h       |  6 ++++
 libavcodec/h264_cabac.c    | 65 ++++++++++++++++++++++++++++++++++++++
 libavcodec/h264_cavlc.c    | 65 ++++++++++++++++++++++++++++++++++++++
 libavcodec/h264_mvpred.h   | 24 ++++++++++++++
 libavcodec/h264_ps.c       |  2 ++
 libavcodec/h264_ps.h       |  2 ++
 libavcodec/h264_slice.c    |  8 +++++
 libavcodec/h264dec.c       | 37 ++++++++++++++++++++++
 libavcodec/h264dec.h       |  1 +
 libavcodec/hevc_refs.c     |  7 ++++
 libavcodec/hevcdec.c       | 51 ++++++++++++++++++++++++++++++
 libavcodec/libx264.c       |  9 ++++++
 libavcodec/mpegutils.c     |  2 ++
 libavcodec/options_table.h |  3 ++
 libavcodec/pthread_frame.c |  1 +
 libavutil/frame.c          |  2 ++
 libavutil/frame.h          | 60 +++++++++++++++++++++++++++++++++++
 20 files changed, 450 insertions(+)

diff --git a/fftools/ffmpeg.c b/fftools/ffmpeg.c
index a2d2f940f5..d7fd06f13a 100644
--- a/fftools/ffmpeg.c
+++ b/fftools/ffmpeg.c
@@ -151,6 +151,7 @@ int        nb_input_files   = 0;
 
 OutputStream **output_streams = NULL;
 int         nb_output_streams = 0;
+int         nb_output_video_streams = 0;
 OutputFile   **output_files   = NULL;
 int         nb_output_files   = 0;
 
@@ -1067,6 +1068,8 @@ static void do_video_out(OutputFile *of,
     int frame_size = 0;
     InputStream *ist = NULL;
     AVFilterContext *filter = ost->filter->filter;
+    int next_duplicate = 0;
+    int dup_frame_mode = 1;
 
     if (ost->source_index >= 0)
         ist = input_streams[ost->source_index];
@@ -1195,6 +1198,13 @@ static void do_video_out(OutputFile *of,
     }
     ost->last_dropped = nb_frames == nb0_frames && next_picture;
 
+    if( (enc->i_use_remv||enc->i_jnd_decqp) && nb_frames == 0 && next_picture )
+    {
+        next_picture->myFrame->output_stream_drop_count++;
+        if ( next_picture->myFrame->output_stream_drop_count == nb_output_video_streams )
+            free( next_picture->myFrame );
+    }
+
     /* duplicates frame if needed */
     for (i = 0; i < nb_frames; i++) {
         AVFrame *in_picture;
@@ -1206,9 +1216,47 @@ static void do_video_out(OutputFile *of,
 
         if (i < nb0_frames && ost->last_frame) {
             in_picture = ost->last_frame;
+            if( enc->i_use_remv||enc->i_jnd_decqp )
+            {
+                if( in_picture->myFrame->is_dup_frame == 0 )
+                    dup_frame_mode = in_picture->myFrame->num_reorder_frames > 0;
+                else
+                    dup_frame_mode = in_picture->myFrame->is_dup_frame!=1;
+                in_picture->myFrame = (FrameReuse*)malloc(sizeof(FrameReuse));
+                in_picture->myFrame->i_frame = -1; //dup frame
+                if( dup_frame_mode )
+                {
+                    in_picture->myFrame->is_dup_frame = 2;
+                    in_picture->myFrame->i_frame_type = (nb_frames > 16)?2:3;
+                }
+                else
+                    in_picture->myFrame->is_dup_frame = 1;
+            }
         } else
+        {
             in_picture = next_picture;
 
+            if( enc->i_use_remv||enc->i_jnd_decqp )
+            {
+                if(next_duplicate++)
+                {
+                    if( in_picture->myFrame->is_dup_frame == 0 )
+                        dup_frame_mode = in_picture->myFrame->num_reorder_frames > 0;
+                    else
+                        dup_frame_mode = in_picture->myFrame->is_dup_frame!=1;
+                    in_picture->myFrame = (FrameReuse*)malloc(sizeof(FrameReuse));
+                    in_picture->myFrame->i_frame = -1; //dup frame
+                    if( dup_frame_mode )
+                    {
+                        in_picture->myFrame->is_dup_frame = 2;
+                        in_picture->myFrame->i_frame_type = (nb_frames > 16)?2:3;
+                    }
+                    else
+                        in_picture->myFrame->is_dup_frame = 1;
+                }
+            }
+        }
+
         if (!in_picture)
             return;
 
@@ -1229,6 +1277,12 @@ static void do_video_out(OutputFile *of,
         } else
             mux_par->field_order = AV_FIELD_PROGRESSIVE;
 
+        if (ost->enc_ctx->i_use_remv && in_picture->myFrame)
+        {
+            in_picture->myFrame->output_stream_count = 0;
+            in_picture->myFrame->output_stream_num = nb_output_video_streams;
+        }
+
         in_picture->quality = enc->global_quality;
         in_picture->pict_type = 0;
 
@@ -2424,6 +2478,7 @@ static int decode_video(InputStream *ist, AVPacket *pkt, int *got_output, int64_
         decoded_frame->top_field_first = ist->top_field_first;
 
     ist->frames_decoded++;
+    input_streams[0]->dec_ctx->myFrame = decoded_frame->myFrame;
 
     if (ist->hwaccel_retrieve_data && decoded_frame->format == ist->hwaccel_pix_fmt) {
         err = ist->hwaccel_retrieve_data(ist->dec_ctx, decoded_frame);
@@ -3515,6 +3570,9 @@ static int init_output_stream(OutputStream *ost, char *error, int error_len)
             }
         }
 
+        if (ost->enc->type == AVMEDIA_TYPE_VIDEO )
+            ost->enc_ctx->myFrame = input_streams[0]->dec_ctx->myFrame;//should be a global myframe buf
+
         if ((ret = avcodec_open2(ost->enc_ctx, codec, &ost->encoder_opts)) < 0) {
             if (ret == AVERROR_EXPERIMENTAL)
                 abort_codec_experimental(codec, 1);
diff --git a/fftools/ffmpeg.h b/fftools/ffmpeg.h
index 7b6f802082..0b64b60ea8 100644
--- a/fftools/ffmpeg.h
+++ b/fftools/ffmpeg.h
@@ -571,6 +571,7 @@ extern int        nb_input_files;
 
 extern OutputStream **output_streams;
 extern int         nb_output_streams;
+extern int         nb_output_video_streams;
 extern OutputFile   **output_files;
 extern int         nb_output_files;
 
diff --git a/fftools/ffmpeg_opt.c b/fftools/ffmpeg_opt.c
index 4efdec702a..22cf4a3633 100644
--- a/fftools/ffmpeg_opt.c
+++ b/fftools/ffmpeg_opt.c
@@ -122,6 +122,9 @@ static int input_stream_potentially_available = 0;
 static int ignore_unknown_streams = 0;
 static int copy_unknown_streams = 0;
 static int find_stream_info = 1;
+static int cmd_i_use_remv      = 0;
+static int cmd_i_use_remv_fref = 0;
+static int cmd_i_jnd_decqp    = 0;
 
 static void uninit_options(OptionsContext *o)
 {
@@ -1368,6 +1371,22 @@ static OutputStream *new_output_stream(OptionsContext *o, AVFormatContext *oc, e
         st->id = o->streamid_map[oc->nb_streams - 1];
 
     GROW_ARRAY(output_streams, nb_output_streams);
+
+    if (type == AVMEDIA_TYPE_VIDEO)
+    {
+        int is_yadiff = 0;
+        for (int i = 0; i < nb_filtergraphs; i++)
+            if (filtergraphs[i]->graph_desc)
+            {
+                is_yadiff = (strstr(filtergraphs[i]->graph_desc, "yadif=1") != NULL ? 1 : 0);
+                break;
+            }
+        if (is_yadiff)
+            nb_output_video_streams+=2;
+        else
+            nb_output_video_streams++;
+    }
+
     if (!(ost = av_mallocz(sizeof(*ost))))
         exit_program(1);
     output_streams[nb_output_streams - 1] = ost;
@@ -3268,6 +3287,27 @@ static int open_files(OptionGroupList *l, const char *inout,
         init_options(&o);
         o.g = g;
 
+        if( cmd_i_use_remv > 0 )
+        {
+            char cmd_us_use_remv[2];
+            sprintf(cmd_us_use_remv, "%d", cmd_i_use_remv);
+            av_dict_set(&((&o)->g->codec_opts), "mvreuse", cmd_us_use_remv, 0);
+        }
+
+        if( cmd_i_use_remv_fref > 0 )
+        {
+            char cmd_us_use_remv_fref[2];
+            sprintf(cmd_us_use_remv_fref, "%d", cmd_i_use_remv_fref);
+            av_dict_set(&((&o)->g->codec_opts), "mvreuse-fref", cmd_us_use_remv_fref, 0);
+        }
+
+        if( cmd_i_jnd_decqp > 0 )
+        {
+            char cmd_us_cdef_decqp[2];
+            sprintf(cmd_us_cdef_decqp, "%d", cmd_i_jnd_decqp);
+            av_dict_set(&((&o)->g->codec_opts), "jnd-decqp", cmd_us_cdef_decqp, 0);
+        }
+
         ret = parse_optgroup(&o, g);
         if (ret < 0) {
             av_log(NULL, AV_LOG_ERROR, "Error parsing options for %s file "
@@ -3645,6 +3685,12 @@ const OptionDef options[] = {
     { "autorotate",       HAS_ARG | OPT_BOOL | OPT_SPEC |
                           OPT_EXPERT | OPT_INPUT,                                { .off = OFFSET(autorotate) },
         "automatically insert correct rotate filters" },
+    { "mvreuse",          HAS_ARG | OPT_INT,                                     { &cmd_i_use_remv },
+        "MVReuse strategy (0:close 1:gain 2:fast 3:balance 4:custom)", "number" },
+    { "mvreuse-fref",     HAS_ARG | OPT_INT,                                     { &cmd_i_use_remv_fref },
+        "Force ref num while MVReuse", "number" },
+    { "jnd-decqp",       HAS_ARG | OPT_INT,                                     { &cmd_i_jnd_decqp },
+        "Adaptive CDEF by decode qp", "number" },
 
     /* audio options */
     { "aframes",        OPT_AUDIO | HAS_ARG  | OPT_PERFILE | OPT_OUTPUT,           { .func_arg = opt_audio_frames },
diff --git a/libavcodec/avcodec.h b/libavcodec/avcodec.h
index d234271c5b..3e3c5448a8 100644
--- a/libavcodec/avcodec.h
+++ b/libavcodec/avcodec.h
@@ -3370,6 +3370,12 @@ typedef struct AVCodecContext {
      * - encoding: unused
      */
     int discard_damaged_percentage;
+    // /* MVReuse info */
+    int i_input_number;
+    FrameReuse *myFrame;
+    int i_use_remv;
+    int i_use_remv_fref;
+    int i_jnd_decqp;
 } AVCodecContext;
 
 #if FF_API_CODEC_GET_SET
diff --git a/libavcodec/h264_cabac.c b/libavcodec/h264_cabac.c
index 815149a501..ea6a1767e7 100644
--- a/libavcodec/h264_cabac.c
+++ b/libavcodec/h264_cabac.c
@@ -2325,6 +2325,65 @@ decode_intra_mb:
         write_back_motion(h, sl, mb_type);
    }
 
+   if(h->avctx->i_use_remv == 2 || h->avctx->i_use_remv == 3 || h->avctx->i_use_remv == 4)
+   {
+        int i, direction;
+        MVReuse *myMb = &(h->cur_pic_ptr->f->myFrame->myMb[sl->mb_x][sl->mb_y]);
+        int direction_max = ((h->cur_pic.f->pict_type==AV_PICTURE_TYPE_P)?1:2);
+        const int b_stride      = h->b_stride;
+        const int b_xy  = 4 * sl->mb_x + 4 * sl->mb_y * h->b_stride; // try mb2b(8)_xy
+        const int b8_xy = 4 * sl->mb_xy;
+        for (direction = 0; direction < direction_max; direction++) {
+            if (IS_8X8(mb_type)) {
+                myMb->i_type = 5;
+                myMb->i_part = 13;
+                for (i = 0; i < 4; i++) {
+                    myMb->sub_mb[i].mv[direction][0] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][0];
+                    myMb->sub_mb[i].mv[direction][1] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][1];
+                    int ref = h->cur_pic.ref_index[direction][b8_xy+i];
+                    myMb->sub_mb[i].i_ref[direction] = (ref==-1)?0:ref;
+                }
+            }
+            else if (IS_16X8(mb_type)) {
+                myMb->i_type = 4;
+                myMb->i_part = 14;
+                for (i = 0; i < 2; i++) {
+                    myMb->sub_mb[i].mv[direction][0] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][0];
+                    myMb->sub_mb[i].mv[direction][1] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][1];
+                    int ref = h->cur_pic.ref_index[direction][b8_xy+(i*2)];
+                    myMb->sub_mb[i].i_ref[direction] = (ref==-1)?0:ref;
+                    if (IS_INTERLACED(mb_type))
+                        myMb->sub_mb[i].mv[direction][1]*=2;
+                }
+            }
+            else if (IS_8X16(mb_type)) {
+                myMb->i_type = 4;
+                myMb->i_part = 15;
+                for (i = 0; i < 2; i++) {
+                    myMb->sub_mb[i].mv[direction][0] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][0];
+                    myMb->sub_mb[i].mv[direction][1] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][1];
+                    int ref = h->cur_pic.ref_index[direction][b8_xy+(i*2)];
+                    myMb->sub_mb[i].i_ref[direction] = (ref==-1)?0:ref;
+                    if (IS_INTERLACED(mb_type))
+                        myMb->sub_mb[i].mv[direction][1]*=2;
+                }
+            }
+            else if (IS_16X16(mb_type)) {
+                myMb->i_type = 4;
+                myMb->i_part = 16;
+                myMb->sub_mb[0].mv[direction][0] = h->cur_pic.motion_val[direction][b_xy][0];
+                myMb->sub_mb[0].mv[direction][1] = h->cur_pic.motion_val[direction][b_xy][1];
+                int ref = h->cur_pic.ref_index[direction][b8_xy];
+                myMb->sub_mb[0].i_ref[direction] = (ref==-1)?0:ref;
+            }
+            else
+            {
+                myMb->i_type = 0;
+                myMb->i_part = 0;
+            }
+        }
+    }
+
     if( !IS_INTRA16x16( mb_type ) ) {
         cbp  = decode_cabac_mb_cbp_luma(sl);
         if(decode_chroma)
@@ -2489,5 +2548,11 @@ decode_intra_mb:
     h->cur_pic.qscale_table[mb_xy] = sl->qscale;
     write_back_non_zero_count(h, sl);
 
+    if(h->avctx->i_jnd_decqp || h->avctx->i_use_remv)
+    {
+        h->cur_pic_ptr->f->myFrame->myMb[sl->mb_x][sl->mb_y].i_skip_qp_get_flag = 1;//non-skip qp get flag
+        h->cur_pic_ptr->f->myFrame->myMb[sl->mb_x][sl->mb_y].i_qp_aq = sl->qscale;
+    }
+
     return 0;
 }
diff --git a/libavcodec/h264_cavlc.c b/libavcodec/h264_cavlc.c
index 6481992e58..6d85d05021 100644
--- a/libavcodec/h264_cavlc.c
+++ b/libavcodec/h264_cavlc.c
@@ -1066,6 +1066,65 @@ decode_intra_mb:
     if(IS_INTER(mb_type))
         write_back_motion(h, sl, mb_type);
 
+    if(h->avctx->i_use_remv == 2 || h->avctx->i_use_remv == 3 || h->avctx->i_use_remv == 4)
+    {
+        int i, direction;
+        MVReuse *myMb = &(h->cur_pic_ptr->f->myFrame->myMb[sl->mb_x][sl->mb_y]);
+        int direction_max = ((h->cur_pic.f->pict_type==AV_PICTURE_TYPE_P)?1:2);
+        const int b_stride      = h->b_stride;
+        const int b_xy  = 4 * sl->mb_x + 4 * sl->mb_y * h->b_stride; // try mb2b(8)_xy
+        const int b8_xy = 4 * sl->mb_xy;
+        for (direction = 0; direction < direction_max; direction++) {
+            if (IS_8X8(mb_type)) {
+                myMb->i_type = 5;
+                myMb->i_part = 13;
+                for (i = 0; i < 4; i++) {
+                    myMb->sub_mb[i].mv[direction][0] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][0];
+                    myMb->sub_mb[i].mv[direction][1] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][1];
+                    int ref = h->cur_pic.ref_index[direction][b8_xy+i];
+                    myMb->sub_mb[i].i_ref[direction] = (ref==-1)?0:ref;
+                }
+            }
+            else if (IS_16X8(mb_type)) {
+                myMb->i_type = 4;
+                myMb->i_part = 14;
+                for (i = 0; i < 2; i++) {
+                    myMb->sub_mb[i].mv[direction][0] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][0];
+                    myMb->sub_mb[i].mv[direction][1] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][1];
+                    int ref = h->cur_pic.ref_index[direction][b8_xy+(i*2)];
+                    myMb->sub_mb[i].i_ref[direction] = (ref==-1)?0:ref;
+                    if (IS_INTERLACED(mb_type))
+                        myMb->sub_mb[i].mv[direction][1]*=2;
+                }
+            }
+            else if (IS_8X16(mb_type)) {
+                myMb->i_type = 4;
+                myMb->i_part = 15;
+                for (i = 0; i < 2; i++) {
+                    myMb->sub_mb[i].mv[direction][0] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][0];
+                    myMb->sub_mb[i].mv[direction][1] = h->cur_pic.motion_val[direction][b_xy+i*b_stride][1];
+                    int ref = h->cur_pic.ref_index[direction][b8_xy+(i*2)];
+                    myMb->sub_mb[i].i_ref[direction] = (ref==-1)?0:ref;
+                    if (IS_INTERLACED(mb_type))
+                        myMb->sub_mb[i].mv[direction][1]*=2;
+                }
+            }
+            else if (IS_16X16(mb_type)) {
+                myMb->i_type = 4;
+                myMb->i_part = 16;
+                myMb->sub_mb[0].mv[direction][0] = h->cur_pic.motion_val[direction][b_xy][0];
+                myMb->sub_mb[0].mv[direction][1] = h->cur_pic.motion_val[direction][b_xy][1];
+                int ref = h->cur_pic.ref_index[direction][b8_xy];
+                myMb->sub_mb[0].i_ref[direction] = (ref==-1)?0:ref;
+            }
+            else
+            {
+                myMb->i_type = 0;
+                myMb->i_part = 0;
+            }
+        }
+    }
+
     if(!IS_INTRA16x16(mb_type)){
         cbp= get_ue_golomb(&sl->gb);
 
@@ -1183,5 +1242,11 @@ decode_intra_mb:
     h->cur_pic.qscale_table[mb_xy] = sl->qscale;
     write_back_non_zero_count(h, sl);
 
+    if(h->avctx->i_jnd_decqp || h->avctx->i_use_remv)
+    {
+        h->cur_pic_ptr->f->myFrame->myMb[sl->mb_x][sl->mb_y].i_skip_qp_get_flag = 1;//non-skip qp get flag
+        h->cur_pic_ptr->f->myFrame->myMb[sl->mb_x][sl->mb_y].i_qp_aq = sl->qscale;
+    }
+
     return 0;
 }
diff --git a/libavcodec/h264_mvpred.h b/libavcodec/h264_mvpred.h
index bf395e3fe2..b13f607548 100644
--- a/libavcodec/h264_mvpred.h
+++ b/libavcodec/h264_mvpred.h
@@ -831,6 +831,30 @@ static void av_unused decode_mb_skip(const H264Context *h, H264SliceContext *sl)
     h->cur_pic.qscale_table[mb_xy] = sl->qscale;
     h->slice_table[mb_xy]          = sl->slice_num;
     sl->prev_mb_skipped            = 1;
+
+    if(h->avctx->i_use_remv == 2 || h->avctx->i_use_remv == 3 || h->avctx->i_use_remv == 4) //for skip
+    {
+        int direction;
+        MVReuse *myMb = &(h->cur_pic_ptr->f->myFrame->myMb[sl->mb_x][sl->mb_y]);
+        int direction_max = ((h->cur_pic.f->pict_type==AV_PICTURE_TYPE_P)?1:2);
+        const int b_stride      = h->b_stride;
+        const int b_xy  = 4 * sl->mb_x + 4 * sl->mb_y * h->b_stride; // try mb2b(8)_xy
+        const int b8_xy = 4 * sl->mb_xy;
+        for (direction = 0; direction < direction_max; direction++) {
+            myMb->i_type = 6;
+            myMb->i_part = 16;
+            myMb->sub_mb[0].mv[direction][0] = h->cur_pic.motion_val[direction][b_xy][0];
+            myMb->sub_mb[0].mv[direction][1] = h->cur_pic.motion_val[direction][b_xy][1];
+            int ref = h->cur_pic.ref_index[direction][b8_xy];
+            myMb->sub_mb[0].i_ref[direction] = (ref==-1)?0:ref;
+        }
+    }
+
+    if(h->avctx->i_jnd_decqp || h->avctx->i_use_remv)
+    {
+        h->cur_pic_ptr->f->myFrame->myMb[sl->mb_x][sl->mb_y].i_skip_qp_get_flag = 0;//skip qp get flag
+        h->cur_pic_ptr->f->myFrame->myMb[sl->mb_x][sl->mb_y].i_qp_aq = sl->qscale;//skip qp get
+    }
 }
 
 #endif /* AVCODEC_H264_MVPRED_H */
diff --git a/libavcodec/h264_ps.c b/libavcodec/h264_ps.c
index e8738d8502..c06891f6ad 100644
--- a/libavcodec/h264_ps.c
+++ b/libavcodec/h264_ps.c
@@ -368,6 +368,7 @@ int ff_h264_decode_seq_parameter_set(GetBitContext *gb, AVCodecContext *avctx,
         goto fail;
     }
 
+    ps->sps_id                = sps_id;
     sps->sps_id               = sps_id;
     sps->time_offset_length   = 24;
     sps->profile_idc          = profile_idc;
@@ -752,6 +753,7 @@ int ff_h264_decode_picture_parameter_set(GetBitContext *gb, AVCodecContext *avct
         return AVERROR_INVALIDDATA;
     }
 
+    ps->pps_id = pps_id;
     pps_buf = av_buffer_allocz(sizeof(*pps));
     if (!pps_buf)
         return AVERROR(ENOMEM);
diff --git a/libavcodec/h264_ps.h b/libavcodec/h264_ps.h
index 9014326dfb..aec5768c23 100644
--- a/libavcodec/h264_ps.h
+++ b/libavcodec/h264_ps.h
@@ -144,6 +144,8 @@ typedef struct H264ParamSets {
     /* currently active parameters sets */
     const PPS *pps;
     const SPS *sps;
+    int sps_id; //get sps for mvreuse
+    int pps_id; //get pps for mvreuse
 } H264ParamSets;
 
 /**
diff --git a/libavcodec/h264_slice.c b/libavcodec/h264_slice.c
index ff46cf9f77..0cf75b937c 100644
--- a/libavcodec/h264_slice.c
+++ b/libavcodec/h264_slice.c
@@ -234,6 +234,13 @@ static int alloc_picture(H264Context *h, H264Picture *pic)
     pic->mb_type      = (uint32_t*)pic->mb_type_buf->data + 2 * h->mb_stride + 1;
     pic->qscale_table = pic->qscale_table_buf->data + 2 * h->mb_stride + 1;
 
+    if( h->avctx->i_use_remv||h->avctx->i_jnd_decqp )
+    {
+        pic->f->myFrame = (FrameReuse*)malloc(sizeof(FrameReuse));
+        pic->f->myFrame->output_stream_drop_count = 0;
+        pic->f->myFrame->is_dup_frame = 0;
+    }
+
     for (i = 0; i < 2; i++) {
         pic->motion_val_buf[i] = av_buffer_pool_get(h->motion_val_pool);
         pic->ref_index_buf[i]  = av_buffer_pool_get(h->ref_index_pool);
@@ -500,6 +507,7 @@ static int h264_frame_start(H264Context *h)
     pic->f->crop_right  = h->crop_right;
     pic->f->crop_top    = h->crop_top;
     pic->f->crop_bottom = h->crop_bottom;
+    pic->f->bref        = (h->nal_ref_idc==0)?0:1;
 
     if ((ret = alloc_picture(h, pic)) < 0)
         return ret;
diff --git a/libavcodec/h264dec.c b/libavcodec/h264dec.c
index 062e3adfc1..5a3fe7a6ca 100644
--- a/libavcodec/h264dec.c
+++ b/libavcodec/h264dec.c
@@ -914,6 +914,43 @@ static int finalize_frame(H264Context *h, AVFrame *dst, H264Picture *out, int *g
         if (ret < 0)
             return ret;
 
+        if (h->avctx->i_use_remv || h->avctx->i_jnd_decqp) {
+
+            H264ParamSets *ps                  = &(((H264Context*)(h->avctx)->priv_data)->ps);
+            SPS *sps                           = (SPS*)(ps->sps_list[ps->sps->sps_id]->data);
+            PPS *pps                           = (PPS*)(ps->pps_list[ps->sps->sps_id]->data);
+            dst->myFrame->i_frame              = h->avctx->i_input_number - h->avctx->has_b_frames;
+            dst->myFrame->num_reorder_frames   = (h->avctx->has_b_frames>0)?1:0;
+            dst->myFrame->ref_max              = sps->ref_frame_count;
+            if(sps->num_units_in_tick != 0)
+                dst->myFrame->framerate            = sps->time_scale / sps->num_units_in_tick / 2;
+            dst->myFrame->ref_count[0]         = pps->ref_count[0];
+            dst->myFrame->ref_count[1]         = pps->ref_count[1];
+            dst->myFrame->weighted_pred        = pps->weighted_pred?1:0;
+            if(dst->pict_type == 3)
+                dst->myFrame->i_frame_type    = dst->bref?4:3;
+            else
+                dst->myFrame->i_frame_type    = dst->pict_type;
+            dst->myFrame->in_width            = h->avctx->width;
+            dst->myFrame->in_height           = h->avctx->height;
+            dst->myFrame->is_dup_frame        = 0;
+
+            int qp_count = 0;
+            dst->myFrame->i_frame_avg_qp_aq   = 0;
+            for(int i=0;i<sps->mb_width;i++)
+            {
+                for(int j=0;j<sps->mb_height;j++)
+                {
+                    if(dst->myFrame->myMb[i][j].i_skip_qp_get_flag) //non-skip --VCA
+                    {
+                        dst->myFrame->i_frame_avg_qp_aq+=dst->myFrame->myMb[i][j].i_qp_aq;
+                        qp_count++;
+                    }
+                }
+            }
+            dst->myFrame->i_frame_avg_qp_aq/=qp_count;
+        }
+
         *got_frame = 1;
 
         if (CONFIG_MPEGVIDEO) {
diff --git a/libavcodec/h264dec.h b/libavcodec/h264dec.h
index 1d9723260d..dd3afbadea 100644
--- a/libavcodec/h264dec.h
+++ b/libavcodec/h264dec.h
@@ -161,6 +161,7 @@ typedef struct H264Picture {
     int recovered;          ///< picture at IDR or recovery point + recovery count
     int invalid_gap;
     int sei_recovery_frame_cnt;
+    FrameReuse *myFrame;
 } H264Picture;
 
 typedef struct H264Ref {
diff --git a/libavcodec/hevc_refs.c b/libavcodec/hevc_refs.c
index 7870a72fd6..2d64a2b0d9 100644
--- a/libavcodec/hevc_refs.c
+++ b/libavcodec/hevc_refs.c
@@ -96,6 +96,13 @@ static HEVCFrame *alloc_frame(HEVCContext *s)
         if (!frame->rpl_buf)
             goto fail;
 
+        if( s->avctx->i_use_remv||s->avctx->i_jnd_decqp )
+        {
+            frame->frame->myFrame = (FrameReuse*)malloc(sizeof(FrameReuse));
+            frame->frame->myFrame->output_stream_drop_count = 0;
+            frame->frame->myFrame->is_dup_frame = 0;
+        }
+
         frame->tab_mvf_buf = av_buffer_pool_get(s->tab_mvf_pool);
         if (!frame->tab_mvf_buf)
             goto fail;
diff --git a/libavcodec/hevcdec.c b/libavcodec/hevcdec.c
index 06804fd94b..163745ebea 100644
--- a/libavcodec/hevcdec.c
+++ b/libavcodec/hevcdec.c
@@ -2822,6 +2822,8 @@ static int hevc_frame_start(HEVCContext *s)
     if (ret < 0)
         goto fail;
 
+    s->frame->bref = s->nal_unit_type;
+
     ret = ff_hevc_frame_rps(s);
     if (ret < 0) {
         av_log(s->avctx, AV_LOG_ERROR, "Error constructing the frame RPS.\n");
@@ -3204,12 +3206,37 @@ static int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,
     int new_extradata_size;
     uint8_t *new_extradata;
     HEVCContext *s = avctx->priv_data;
+    AVFrame *pict;
 
     if (!avpkt->size) {
         ret = ff_hevc_output_frame(s, data, 1);
         if (ret < 0)
             return ret;
 
+        if ((s->avctx->i_use_remv || s->avctx->i_jnd_decqp)&&(*got_output)) {
+
+            pict = data;
+
+            HEVCSPS *sps                           = (HEVCSPS*)s->ps.sps;
+            HEVCPPS *pps                           = (HEVCPPS*)s->ps.pps;
+            HEVCVPS *vps                           = (HEVCVPS*)s->ps.vps;
+            pict->myFrame->i_frame              = s->avctx->i_input_number - s->avctx->has_b_frames;
+            pict->myFrame->num_reorder_frames   = (s->avctx->has_b_frames>0)?1:0;//sps->temporal_layer[0].num_reorder_pics;
+            pict->myFrame->ref_max              = log2(sps->log2_max_poc_lsb);
+            // pict->myFrame->framerate            = vps->vps_time_scale / 2;
+            pict->myFrame->ref_count[0]         = pps->num_ref_idx_l0_default_active;
+            pict->myFrame->ref_count[1]         = pps->num_ref_idx_l1_default_active;
+            pict->myFrame->weighted_pred        = pps->weighted_pred_flag;
+            if(pict->pict_type == 1)
+                pict->myFrame->i_frame_type    = (pict->bref==HEVC_NAL_IDR_N_LP)?1:5;
+            else if(pict->pict_type == 3)
+                pict->myFrame->i_frame_type    = (pict->bref==HEVC_NAL_TRAIL_R||pict->bref==HEVC_NAL_RASL_R)?4:3;
+            else
+                pict->myFrame->i_frame_type    = pict->pict_type;
+            pict->myFrame->in_width            = s->avctx->width;
+            pict->myFrame->in_height           = s->avctx->height;
+            pict->myFrame->is_dup_frame        = 0;
+        }
         *got_output = ret;
         return 0;
     }
@@ -3254,6 +3281,30 @@ static int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,
 
     if (s->output_frame->buf[0]) {
         av_frame_move_ref(data, s->output_frame);
+        if (s->avctx->i_use_remv || s->avctx->i_jnd_decqp) {
+
+            pict = data;
+
+            HEVCSPS *sps                           = (HEVCSPS*)s->ps.sps;
+            HEVCPPS *pps                           = (HEVCPPS*)s->ps.pps;
+            HEVCVPS *vps                           = (HEVCVPS*)s->ps.vps;
+            pict->myFrame->i_frame              = s->avctx->i_input_number - s->avctx->has_b_frames;
+            pict->myFrame->num_reorder_frames   = (s->avctx->has_b_frames>0)?1:0;//sps->temporal_layer[0].num_reorder_pics;
+            pict->myFrame->ref_max              = log2(sps->log2_max_poc_lsb);
+            // pict->myFrame->framerate            = vps->vps_time_scale / 2;
+            pict->myFrame->ref_count[0]         = pps->num_ref_idx_l0_default_active;
+            pict->myFrame->ref_count[1]         = pps->num_ref_idx_l1_default_active;
+            pict->myFrame->weighted_pred        = pps->weighted_pred_flag;
+            if(pict->pict_type == 1)
+                pict->myFrame->i_frame_type    = (pict->bref==HEVC_NAL_IDR_N_LP)?1:5;
+            else if(pict->pict_type == 3)
+                pict->myFrame->i_frame_type    = (pict->bref==HEVC_NAL_TRAIL_R||pict->bref==HEVC_NAL_RASL_R)?4:3;
+            else
+                pict->myFrame->i_frame_type    = pict->pict_type;
+            pict->myFrame->in_width            = s->avctx->width;
+            pict->myFrame->in_height           = s->avctx->height;
+            pict->myFrame->is_dup_frame        = 0;
+        }
         *got_output = 1;
     }
 
diff --git a/libavcodec/libx264.c b/libavcodec/libx264.c
index dc4b4b100d..c9958d8e04 100644
--- a/libavcodec/libx264.c
+++ b/libavcodec/libx264.c
@@ -307,6 +307,7 @@ static int X264_frame(AVCodecContext *ctx, AVPacket *pkt, const AVFrame *frame,
         }
 
         x4->pic.i_pts  = frame->pts;
+        x4->pic.myFrame = frame->myFrame;
 
         x4->reordered_opaque[x4->next_reordered_opaque] = frame->reordered_opaque;
         x4->pic.opaque = &x4->reordered_opaque[x4->next_reordered_opaque];
@@ -900,6 +901,14 @@ FF_ENABLE_DEPRECATION_WARNINGS
 
     avctx->bit_rate = x4->params.rc.i_bitrate*1000;
 
+    if( avctx->i_use_remv && detect_avx512() )
+    {
+        x264_param_default_preset_mvreuse(&x4->params, avctx->i_use_remv, avctx->i_jnd_decqp,
+            avctx->myFrame->framerate, avctx->myFrame->num_reorder_frames, avctx->i_use_remv_fref, avctx->myFrame->ref_max, avctx->myFrame->weighted_pred, avctx->gop_size, X264_KEYINT_MAX_INFINITE, avctx->myFrame->in_width, avctx->myFrame->in_height);
+    }
+    else
+        x4->params.i_use_remv = 0;
+
     x4->enc = x264_encoder_open(&x4->params);
     if (!x4->enc)
         return AVERROR_EXTERNAL;
diff --git a/libavcodec/mpegutils.c b/libavcodec/mpegutils.c
index 3f94540616..aa2d57bbec 100644
--- a/libavcodec/mpegutils.c
+++ b/libavcodec/mpegutils.c
@@ -26,6 +26,8 @@
 #include "libavutil/motion_vector.h"
 #include "libavutil/avassert.h"
 
+#include "h264_ps.h"
+#include "h264dec.h"
 #include "avcodec.h"
 #include "mpegutils.h"
 
diff --git a/libavcodec/options_table.h b/libavcodec/options_table.h
index 4a266eca16..1d7e0c2ff4 100644
--- a/libavcodec/options_table.h
+++ b/libavcodec/options_table.h
@@ -481,6 +481,9 @@ static const AVOption avcodec_options[] = {
 {"allow_profile_mismatch", "attempt to decode anyway if HW accelerated decoder's supported profiles do not exactly match the stream", 0, AV_OPT_TYPE_CONST, {.i64 = AV_HWACCEL_FLAG_ALLOW_PROFILE_MISMATCH }, INT_MIN, INT_MAX, V | D, "hwaccel_flags"},
 {"extra_hw_frames", "Number of extra hardware frames to allocate for the user", OFFSET(extra_hw_frames), AV_OPT_TYPE_INT, { .i64 = -1 }, -1, INT_MAX, V|D },
 {"discard_damaged_percentage", "Percentage of damaged samples to discard a frame", OFFSET(discard_damaged_percentage), AV_OPT_TYPE_INT, {.i64 = 95 }, 0, 100, V|D },
+{"mvreuse", "MVReuse strategy (0:close 1:gain 2:fast 3:balance 4:custom)", OFFSET(i_use_remv), AV_OPT_TYPE_INT, {.i64 = 0 }, 0, 4, V|D|E},
+{"mvreuse-fref", "Force ref num while MVReuse", OFFSET(i_use_remv_fref), AV_OPT_TYPE_INT, {.i64 = 0 }, 0, 16, V|D|E},
+{"jnd-decqp", "Adaptive CDEF by decode qp", OFFSET(i_jnd_decqp), AV_OPT_TYPE_INT, {.i64 = 0 }, 0, 1, V|D|E},
 {NULL},
 };
 
diff --git a/libavcodec/pthread_frame.c b/libavcodec/pthread_frame.c
index 36ac0ac1e5..84e1012d05 100644
--- a/libavcodec/pthread_frame.c
+++ b/libavcodec/pthread_frame.c
@@ -339,6 +339,7 @@ static int update_context_from_user(AVCodecContext *dst, AVCodecContext *src)
 
     dst->frame_number     = src->frame_number;
     dst->reordered_opaque = src->reordered_opaque;
+    dst->i_input_number   = src->i_input_number++;
     dst->thread_safe_callbacks = src->thread_safe_callbacks;
 
     if (src->slice_count && src->slice_offset) {
diff --git a/libavutil/frame.c b/libavutil/frame.c
index dcf1fc3d17..6aa4376117 100644
--- a/libavutil/frame.c
+++ b/libavutil/frame.c
@@ -373,6 +373,8 @@ FF_ENABLE_DEPRECATION_WARNINGS
     dst->colorspace             = src->colorspace;
     dst->color_range            = src->color_range;
     dst->chroma_location        = src->chroma_location;
+    dst->bref                   = src->bref;
+    dst->myFrame                = src->myFrame;
 
     av_dict_copy(&dst->metadata, src->metadata, 0);
 
diff --git a/libavutil/frame.h b/libavutil/frame.h
index 5d3231e7bb..77237a5aab 100644
--- a/libavutil/frame.h
+++ b/libavutil/frame.h
@@ -191,6 +191,57 @@ enum AVActiveFormatDescription {
     AV_AFD_SP_4_3       = 15,
 };
 
+/**
+ * MV Reuse.
+ */
+#ifndef _MV_REUSE_
+#define _MV_REUSE_
+
+struct MyInfo {
+    int frame_num;
+    // AVMotionVector *sd;
+    uint32_t *mb_type;
+    int mb_num;
+    int size;
+    uint8_t *data;
+    int my_slice_type;
+    int ref_fra;
+    int ref_flag;
+};
+
+typedef struct MVReuseAVMotionVector {
+    short mv[2][2];
+    int i_ref[2];
+} MVReuseAVMotionVector;
+
+typedef struct MVReuse {
+    int i_type;
+    int i_part;
+    int i_skip_qp_get_flag;
+    int i_qp_aq;
+    MVReuseAVMotionVector sub_mb[4];
+} MVReuse;
+
+typedef struct FrameReuse {
+    int i_frame;
+    int i_frame_type;
+    int weighted_pred;
+    int ref_max;
+    int ref_count[2];
+    int num_reorder_frames;
+    int i_h264_frame_type;
+    int in_width;
+    int in_height;
+    int is_dup_frame;
+    int framerate;
+    float i_frame_avg_qp_aq;
+    int output_stream_count;
+    int output_stream_drop_count;
+    int output_stream_num;
+    MVReuse myMb[300][300];
+    MVReuse myMb_resize[300][300];
+} FrameReuse;
+#endif
 
 /**
  * Structure to hold side data for an AVFrame.
@@ -672,6 +723,15 @@ typedef struct AVFrame {
      * for the target frame's private_ref field.
      */
     AVBufferRef *private_ref;
+    /**
+     * b_reference_frame flag
+     */
+    int bref;
+    /**
+     * MVReuse structure
+     */
+    FrameReuse *myFrame;
+
 } AVFrame;
 
 #if FF_API_FRAME_GET_SET
-- 
2.27.0

